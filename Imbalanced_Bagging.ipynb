{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced_Bagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PFLg9O8s-PIz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using Bagging for an imbalanced classification task"
      ]
    },
    {
      "metadata": {
        "id": "KELaIlAl-ZVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we use the breast cancer data, a naturally imbalanced problem. We will use a Logistic Regression inside a Bagging Classifier. We will see how defining weights for the bootstraping in the Bagging can improve our classification task. The metric we will use here is the balanced accuracy, which has recently been added to scikit-learn. Balanced accuracy is basically an averaged recall score."
      ]
    },
    {
      "metadata": {
        "id": "6nfCo21khYd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4R8nCYnBky9o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Am5G-e9J_dBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cf55ab5-c502-4d38-9d38-47d7fd7ce54c"
      },
      "cell_type": "code",
      "source": [
        "print(\"Size of class 0: %i\" % len(y_train[y_train == 0]))\n",
        "print(\"Size of class 1: %i\" % len(y_train[y_train == 1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of class 0: 164\n",
            "Size of class 1: 262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BhAUTk8z_Uyr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Without weights"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DCRYuiefs9DP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BaggingClassifier(LogisticRegression(solver = 'liblinear'), \n",
        "                          n_estimators=10, \n",
        "                          bootstrap = True, random_state = 2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "321d34cf-ecc3-4a6a-c880-51f1a262a4c7",
        "id": "cuPCHnjQs9DS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
              "          tol=0.0001, verbose=0, warm_start=False),\n",
              "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
              "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
              "         random_state=2019, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0d84ea29-9bb8-4b36-93f8-ecee5a89cbc9",
        "id": "a2DJIKGfs9DX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "balanced_accuracy_score(y_test,model.predict(X_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9214912280701755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "BShiX3Kq_Xdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. With weights"
      ]
    },
    {
      "metadata": {
        "id": "nW0gJ88Jl--B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y0 = len(y_train[y_train == 0])\n",
        "y1 = len(y_train[y_train == 1])\n",
        "\n",
        "w0 = y1/y0\n",
        "w1 = 1\n",
        "\n",
        "sample_weights = np.zeros(len(y_train))\n",
        "sample_weights[y_train == 0] = w0\n",
        "sample_weights[y_train == 1] = w1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "551FTi1Nh6_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BaggingClassifier(LogisticRegression(solver = 'liblinear'), \n",
        "                      n_estimators=10, \n",
        "                      bootstrap = True, random_state = 2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7c1SSHdi8pB",
        "colab_type": "code",
        "outputId": "44a3644c-1f6c-4145-aff2-309f1328cadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,sample_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
              "          tol=0.0001, verbose=0, warm_start=False),\n",
              "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
              "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
              "         random_state=2019, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "E4L_LbOcrz2R",
        "colab_type": "code",
        "outputId": "98b01dbd-a5d6-4852-fd03-5730bc3976d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "balanced_accuracy_score(y_test,model.predict(X_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9423245614035087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "EYBFujeX_u5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conclusion: We have improved our balanced accuracy from **0.92** to **0.94**!"
      ]
    },
    {
      "metadata": {
        "id": "00nRzWdf_1oB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}